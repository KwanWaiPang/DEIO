<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Personal Blog of Kwan Wai-Pang">
  <meta name="keywords" content="SLAM, Event Camera, Robotics">

  <!-- ç¡®ä¿æ‚¨å·²ç»è®¾ç½®äº†è§†å£çš„metaæ ‡ç­¾ç”¨äºŽè‡ªé€‚åº”å±å¹•å¤§å°çš„ -->
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <!-- <title>Kwan Wai-Pang's PhD Thesis</title> -->
  <title>HKU-ArcLab | DEIO</title>
  <meta name="author" content="Kwan Wai-Pang " />

  <!-- OpenGraph ç”¨äºŽæ›´æ–°é¡µé¢-->
  <meta property="og:site_name" content="Kwan Wai-Pang's PhD Thesis" />
  <meta property="og:type" content="website" />
  <meta property="og:title" content="Kwan Wai-Pang | PhD Thesis" />
  <meta property="og:description" content="Welcome to DEIO ðŸ˜Š" />
  <meta property="og:image" content="https://kwanwaipang.github.io/Poster_files/hku_logo.jpg" />

  <meta property="og:locale" content="en" />

  <meta name="google-site-verification" content="Jtxa1xy6N3_2RjVVFrZgXjPZ0AHklxJXQ1eQ6QXNWr8" />

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-R1QX9D95NS"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-R1QX9D95NS');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="https://kwanwaipang.github.io/Poster_files/hku_logo.jpg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          
          <a class="navbar-item" href="https://kwanwaipang.github.io/Mono-EIO">
            Mono-EIO
          </a>

          <a class="navbar-item" href="https://kwanwaipang.github.io/PL-EVIO">
            PL-EVIO
          </a>

          <a class="navbar-item" href="https://kwanwaipang.github.io/ESVIO">
            ESVIO
          </a>


          <a class="navbar-item" href="https://kwanwaipang.github.io/EVI-SAM">
            EVI-SAM
          </a>

          <a class="navbar-item" href="https://kwanwaipang.github.io/DEIO">
            DEIO
          </a>

          <a class="navbar-item" href="https://arclab-hku.github.io/SuperEIO">
            SuperEIO
          </a>

          <a class="navbar-item" target="_blank" href="https://arclab-hku.github.io/ecmd/">
            ECMD Dataset
          </a>

          <a class="navbar-item" target="_blank" href="https://github.com/arclab-hku/Event_based_VO-VIO-SLAM">
            HKU Dataset
          </a>

        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">DEIO: Deep Event Inertial Odometry</h1>

          <!-- ä½œè€… -->
          <div class="is-size-5 publication-authors">

            <span class="author-block">
              <a href="https://kwanwaipang.github.io/" target="_blank">Weipeng Guan</a><sup>1*</sup>,
            </span>


            <span class="author-block">
              <a href="https://github.com/zerolfl" target="_blank">Fuling Lin</a><sup>1*</sup>,
            </span>


            <span class="author-block">
              <a href="https://github.com/cpymaple" target="_blank">Peiyu Chen</a><sup>1</sup>,
            </span>

            <span class="author-block">
              <a href="https://arclab.hku.hk/PengLu.html" target="_blank">Peng Lu</a><sup>1</sup>
            </span>
            
          </div>
          
          <!-- å•ä½ -->
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>The University of Hong Kong</span>
            <br>
            <span class="author-block"><sup>*</sup>Equal Contribution</span>
          </div>

          <!-- å„ç§link -->
          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href=" "
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2411.03928"
                   target="_blank"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=gs_LLOh3AsQ"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/arclab-hku/DEIO"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>

              <!-- Dataset Link. -->
              <!-- <span class="link-block"> -->
                <!-- <a href="  " -->
                    <!-- target="_blank" -->
                   <!-- class="external-link button is-normal is-rounded is-dark"> -->
                  <!-- <span class="icon"> -->
                      <!-- <i class="far fa-images"></i> -->
                  <!-- </span> -->
                  <!-- <span>Data</span> -->
                  <!-- </a> -->
                <!-- </span> -->

            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- å‚è€ƒä»£ç ï¼šhttps://github.com/nerfies/nerfies.github.io/blob/main/index.html -->
<!-- å¯¹åº”ç½‘é¡µæ•ˆæžœï¼šhttps://nerfies.github.io/ -->


<!-- <section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">

        <div class="item item-boxes_6dof">
          <video poster="" id="boxes_6dof" autoplay controls muted loop playsinline height="100%">
            <source src="./static/video/deio_fpv.mp4"
                    type="video/mp4">
          </video>
        </div>
        
        <div class="item item-boxes_6dof">
          <video poster="" id="boxes_6dof" autoplay controls muted loop playsinline height="100%">
            <source src="./static/video/boxes_6dof.mp4"
                    type="video/mp4">
          </video>
        </div>

        <div class="item item-dynamic_6dof">
          <video poster="" id="dynamic_6dof" autoplay controls muted loop playsinline height="100%">
            <source src="./static/video/dynamic_6dof.mp4"
                    type="video/mp4">
          </video>
        </div>

        <div class="item item-boxes_6dof">
          <video poster="" id="boxes_6dof" autoplay controls muted loop playsinline height="100%">
            <source src="./static/video/DEIO_dark_flying.mp4"
                    type="video/mp4">
          </video>
        </div>

        <div class="item item-deio_ecmd">
          <video poster="" id="deio_ecmd" autoplay controls muted loop playsinline height="100%">
            <source src="./static/video/Vicon_dark1.mp4"
                    type="video/mp4">
          </video>
        </div>

        <div class="item item-deio_ecmd">
          <video poster="" id="deio_ecmd" autoplay controls muted loop playsinline height="100%">
            <source src="./static/video/deio_ecmd.mp4"
                    type="video/mp4">
          </video>
        </div>
        

        <div class="item item-HKU_agg_small_flip">
          <video poster="" id="HKU_agg_small_flip" autoplay controls muted loop playsinline height="100%">
            <source src="./static/video/HKU_agg_small_flip.mp4"
                    type="video/mp4">
          </video>
        </div>

        <div class="item item-HKU_agg_small_flip">
          <video poster="" id="HKU_agg_small_flip" autoplay controls muted loop playsinline height="100%">
            <source src="./static/video/HKU_agg_tran.mp4"
                    type="video/mp4">
          </video>
        </div>

      </div>
    </div>
  </div>
</section> -->

<section class="section">
  <div class="container is-max-desktop">

    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">

        <div align="center" style="
          position: relative; 
          width: 100%; 
          height: 450px;
          margin: 0 auto;
          border-radius: 15px;
          background: url('https://kwanwaipang.github.io/File/Representative_works/loading-icon.gif') center/contain no-repeat;
          ">
          <iframe width="100%" height="100%"
            src="//player.bilibili.com/player.html?isOutside=true&aid=114385062199300&bvid=BV1Y5L4zQEn6&cid=29562110953&p=1" 
            title="Bilibili video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen  style="opacity: 0; transition: opacity 0.5s; border-radius: 15px;" onload="this.style.opacity='1'"
          ></iframe>
        </div>

        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
        Event cameras are bio-inspired, motion-activated sensors that demonstrate great potential in handling challenging situations, such as fast motion and high-dynamic range.
        Despite their promise, existing event-based simultaneous localization and mapping (SLAM) approaches still face limited performance in real-world applications.
        On the other hand, state-of-the-art SLAM approaches that incorporate deep neural networks show impressive robustness and applicability.
        However, there is a lack of research on fusing learning-based event SLAM methods with IMU, which could be indispensable to push the event-based SLAM to large-scale, low-texture or complex scenarios. 
        In this paper, we propose DEIO, the first monocular deep event-inertial odometry framework, which combines learning-based method with traditional nonlinear graph-based optimization. 
        Specifically, we tightly integrate a trainable event-based differentiable bundle adjustment (e-DBA) with the IMU pre-integration in a patch-based co-visibility factor graph that employs keyframe-based sliding window optimization.
        Numerical Experiments in ten public challenge datasets demonstrate that our method can achieve superior performance compared with the image-based and event-based benchmarks.  
        </div>

        <div class="content has-text-justified">
        <h2 class="title is-3">Qualitative Evaluation</h2>
        <div align="center">
          <table style="border: none; background-color: transparent;">
            <tr align="center">
              <td style="width: 50%; border: none; padding: 0.01; background-color: transparent; vertical-align: middle;">
                  <video playsinline autoplay loop muted src="./static/video/deio_fpv.mp4" poster="https://kwanwaipang.github.io/File/Representative_works/loading-icon.gif" alt="sym" width="100%" style="padding-top:0px;padding-bottom:0px;border-radius:15px;"></video>
                  indoor_forward_7 in <a href="https://fpv.ifi.uzh.ch/" target="_blank">UZH-FPV</a>
              </td>
              <td style="width: 50%; border: none; padding: 0.01; background-color: transparent; vertical-align: middle;">
                <video playsinline autoplay loop muted src="./static/video/DEIO_dark_flying.mp4" poster="https://kwanwaipang.github.io/File/Representative_works/loading-icon.gif" alt="sym" width="100%" style="padding-top:0px;padding-bottom:0px;border-radius:15px;"></video>
                 Drone Flight in Dark Scene
              </td>
            </tr>
            <tr align="center">
              <td style="width: 50%; border: none; padding: 0.01; background-color: transparent; vertical-align: middle;">
                  <video playsinline autoplay loop muted src="./static/video/dynamic_6dof.mp4" poster="https://kwanwaipang.github.io/File/Representative_works/loading-icon.gif" alt="sym" width="100%" style="padding-top:0px;padding-bottom:0px;border-radius:15px;"></video>
                  dynamic_6dof in <a href="https://rpg.ifi.uzh.ch/davis_data.html" target="_blank">DAVIS240c</a>
              </td>
              <td style="width: 50%; border: none; padding: 0.01; background-color: transparent; vertical-align: middle;">
                <video playsinline autoplay loop muted src="./static/video/boxes_6dof.mp4" poster="https://kwanwaipang.github.io/File/Representative_works/loading-icon.gif" alt="sym" width="100%" style="padding-top:0px;padding-bottom:0px;border-radius:15px;"></video>
                boxes_6dof in <a href="https://rpg.ifi.uzh.ch/davis_data.html" target="_blank">DAVIS240c</a>
              </td>
            </tr>
            <tr align="center">
              <td style="width: 50%; border: none; padding: 0.01; background-color: transparent; vertical-align: middle;">
                  <video playsinline autoplay loop muted src="./static/video/HKU_agg_small_flip.mp4" poster="https://kwanwaipang.github.io/File/Representative_works/loading-icon.gif" alt="sym" width="100%" style="padding-top:0px;padding-bottom:0px;border-radius:15px;"></video>
                  HKU_agg_small_flip in <a href="https://github.com/arclab-hku/Event_based_VO-VIO-SLAM#Dataset-for-stereo-evio" target="_blank">Stereo-HKU</a>
              </td>
              <td style="width: 50%; border: none; padding: 0.01; background-color: transparent; vertical-align: middle;">
                <video playsinline autoplay loop muted src="./static/video/HKU_agg_tran.mp4" poster="https://kwanwaipang.github.io/File/Representative_works/loading-icon.gif" alt="sym" width="100%" style="padding-top:0px;padding-bottom:0px;border-radius:15px;"></video>
                HKU_agg_tran in <a href="https://github.com/arclab-hku/Event_based_VO-VIO-SLAM#Dataset-for-stereo-evio" target="_blank">Stereo-HKU</a>
              </td>
            </tr>
            <tr align="center">
              <td style="width: 50%; border: none; padding: 0.01; background-color: transparent; vertical-align: middle;">
                  <video playsinline autoplay loop muted src="./static/video/Vicon_dark1.mp4" poster="https://kwanwaipang.github.io/File/Representative_works/loading-icon.gif" alt="sym" width="100%" style="padding-top:0px;padding-bottom:0px;border-radius:15px;"></video>
                  Vicon_dark1 in <a href="https://github.com/arclab-hku/Event_based_VO-VIO-SLAM#Dataset-for-monocular-evio" target="_blank">Mono-HKU</a>
              </td>
              <td style="width: 50%; border: none; padding: 0.01; background-color: transparent; vertical-align: middle;">
                <video playsinline autoplay loop muted src="./static/video/deio_ecmd.mp4" poster="https://kwanwaipang.github.io/File/Representative_works/loading-icon.gif" alt="sym" width="100%" style="padding-top:0px;padding-bottom:0px;border-radius:15px;"></video>
                Dense_street_night_easy_a in <a href="https://arclab-hku.github.io/ecmd/" target="_blank">ECMD</a>
              </td>
            </tr>
          </table>
          <figcaption>
          </figcaption>
        </div>

        <h2 class="title is-3">Qualitative Comparison Against GT</h2>
        <div align="center">
        <img src="./static/img/deio_davis240c.png" width="100%" />
        <figcaption class="content has-text-justified">  
        Comparison of the estimated position (X, Y, Z) and orientation (Roll, Pitch, Yaw) results of our DEIO with DEVO in the sequence of (a) boxes_6dof and (b) poster_6dof from the <a href="https://rpg.ifi.uzh.ch/davis_data.html" target="_blank">DAVIS240c</a> dataset. 
          The DEIO efficiently converts scale ambiguity and aligns closely with the ground truth trajectory.
        </figcaption>
        </div>

        <br>
        <div align="center">
        <img src="./static/img/deio_hku_dataset.png" width="100%" />
        <figcaption class="content has-text-justified">  
          Comparison of the estimated trajectories (in X, Y, Z, and XY-plane) with DEVO in the Mono & Stereo <a href="https://github.com/arclab-hku/Event_based_VO-VIO-SLAM" target="_blank">HKU dataset</a>. 
        The DEIO seamlessly addresses scale ambiguity and demonstrates precise alignment with the ground truth trajectory.
        In contrast, the baseline estimates exhibit significant scale discrepancies:
        (a) The baseline trajectory suffers from drift and an overestimated scale.
        (b) The baseline trajectory shows an underestimated scale.
        </figcaption>
        </div>

         <br>
        <div align="center">
        <img src="./static/img/deio_eds.png" width="100%" />
        <figcaption class="content has-text-justified">  
          The estimated trajectories of our DEIO against the GT in the sequence of ziggy_hdr and rocket_dark from the <a href="https://rpg.ifi.uzh.ch/eds.html" target="_blank">EDS</a>  dataset. 
        The image view (visualization-only) demonstrates the lack of perceptible information under low-light conditions, while the event view, though perceptible, remains susceptible to interference from the infrared light of the motion capture system. 
        Thanks to our robust learning-based event data association, the trajectories estimated by DEIO align remarkably closely with the GT.
        </figcaption>
        </div>

        <br>
        <div align="center">
        <img src="./static/img/deio_fpv.png" width="100%" />
        <figcaption class="content has-text-justified">  
          The estimated trajectories (X, Y, Z, Roll, Pitch, Yaw) of our DEIO against the GT in the sequence of indoor_forward_7 from the <a href="https://fpv.ifi.uzh.ch/" target="_blank">UZH-FPV</a> dataset. 
        The image view (visualization-only) demonstrates the condition under low texture, HDR, and motion blur.
        </figcaption>
        </div>

        <br>
        <div align="center">
        <img src="./static/img/deio_dsec.png" width="100%" />
        <figcaption class="content has-text-justified">  
         Visualization of estimated trajectories in the <a href="https://dsec.ifi.uzh.ch/" target="_blank">DSEC</a> dataset.
         Despite using a monocular setup, our DEIO results align more closely with the ground truth compared to other methods, which utilize a stereo setup.
        </figcaption>
        </div>
        </div>  
        
         <div class="content has-text-justified">
        <h2 class="title is-3">Evaluation in Night Driving Scenarios</h2>
        Driving scenarios pose challenges for event-based state estimation, especially at nighttime, where rampant flickering light (e.g., from LED signs) generates an overwhelming number of noisy events.
        Additionally, the movement of vehicles, such as sharp turns, sudden stops, and other abrupt movements, can further complicate the event-based estimator.
        In this section, we select the Dense_street_night_easy_a sequences of the ECMD dataset, which feature numerous flashing lights from vehicles, street signs, buildings, and moving vehicles, making event-based SLAM more difficult.
        This dataset is recorded with two pairs of stereo event cameras (640 X 480 and 346 X 260) on a car driven through various road conditions such as streets, highways, roads, and tunnels in Hong Kong.
        Our DEIO runs on the event from the DAVIS346 and the IMU sensor, while the image frame output of the DAVIS346 is only used for illustration purposes.
        The following figure shows a small drift with a 4.7 m error of our estimated trajectory on the 620 m drive.
        To the best of our knowledge, we present the first results on pose tracking for night driving scenarios using event and IMU odometry. 
        The earliest attempt in this area is ESVIO, which utilizes a combination of stereo events, stereo images, and IMU data, whereas DEIO operates with a monocular setup.
        </div>

        <div align="center">
          <img src="./static/img/driving_testing.png" width="100%" />
        <figcaption>  
        The estimated trajectory of our DEIO in the night driving scenarios and its comparison against the GNSS-INS-RTK as ground truth.
        The image view is for visualization only.
        </figcaption>
        </div>

        <br><br>
        <div class="content has-text-justified">
        <h2 class="title is-3">Evaluation in Dark Quadrotor-Flight</h2>
        We evaluate our DEIO in a dark quadrotor flight experiment.
        The quadrotor is commanded to track a circle pattern with 1.5 m in radius and 1.8 m in height.
        The illuminance in the environment is quite low, resulting in minimal visual information captured by the onboard camera.
        The total length of the trajectory is 60.7 m, with an MPE of 0.15 and an average pose tracking error of 9 cm.
        % We further illustrate the estimated trajectories (translation and rotation) of our DEIO against the ground truth, as well as their corresponding errors. 
        The translation errors in the X, Y, and Z dimensions are all within 0.5 m, while the rotation errors of the Roll and Pitch dimensions are within 6<sup>0</sup>, and the one in the Yaw dimension is within 3<sup>0</sup>.
        To the best of our knowledge, this is also the first implementation of monocular event-inertial odometry for pose tracking in dark flight environments, while the previous works rely on the image-aided event-IMU estimators.
        </div>

        <div align="center">
          <img src="./static/img/flighting_testing.png" width="100%" />
        <figcaption>  
        (a) Testing evaluation (the image is for visualization only).
        (b) The estimated trajectory of our DEIO in the quadrotor flight and its comparison against the ground truth.
        </figcaption>
        </div>
        
      </div>      
    </div>
    <!--/ Abstract. -->
  </div>
</section>




<!-- å¼•ç”¨æ ¼å¼ -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
      @article{GWPHKU:DEIO,
        title={DEIO: Deep Event Inertial Odometry},
        author={Guan, Weipeng and Lin, Fuling and Chen, Peiyu and Lu, Peng},
        journal={arXiv preprint arXiv:2411.03928},
        year={2024}
      }
    </code></pre>
  </div>
</section>


<!-- é¡µè„š -->
<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
            <br>
            This website template is from <a
            href="https://github.com/nerfies/nerfies.github.io">source code</a>.
            We sincerely thank the author for developing and open-sourcing this template.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>


<!-- <script> -->
<!--  -->
  <!-- // å½“ iframe åŠ è½½å®ŒæˆåŽæ‰§è¡Œ -->
  <!-- document.getElementById('videoIframe1').onload = function() { -->
      <!-- // éšè—åŠ è½½ä¸­çš„åŠ¨å›¾ -->
      <!-- document.getElementById('loadingImage1').style.display = 'none'; -->
      <!-- // æ˜¾ç¤º iframe -->
      <!-- document.getElementById('videoIframe1').style.display = 'block'; -->
  <!-- }; -->
<!--  -->
  <!-- document.getElementById('videoIframe2').onload = function() { -->
      <!-- // éšè—åŠ è½½ä¸­çš„åŠ¨å›¾ -->
      <!-- document.getElementById('loadingImage2').style.display = 'none'; -->
      <!-- // æ˜¾ç¤º iframe -->
      <!-- document.getElementById('videoIframe2').style.display = 'block'; -->
  <!-- }; -->
<!--  -->
  <!-- document.getElementById('videoIframe3').onload = function() { -->
      <!-- // éšè—åŠ è½½ä¸­çš„åŠ¨å›¾ -->
      <!-- document.getElementById('loadingImage3').style.display = 'none'; -->
      <!-- // æ˜¾ç¤º iframe -->
      <!-- document.getElementById('videoIframe3').style.display = 'block'; -->
  <!-- }; -->
<!--  -->
  <!-- document.getElementById('videoIframe4').onload = function() { -->
      <!-- // éšè—åŠ è½½ä¸­çš„åŠ¨å›¾ -->
      <!-- document.getElementById('loadingImage4').style.display = 'none'; -->
      <!-- // æ˜¾ç¤º iframe -->
      <!-- document.getElementById('videoIframe4').style.display = 'block'; -->
  <!-- }; -->
<!--  -->
  <!-- document.getElementById('videoIframe5').onload = function() { -->
      <!-- // éšè—åŠ è½½ä¸­çš„åŠ¨å›¾ -->
      <!-- document.getElementById('loadingImage5').style.display = 'none'; -->
      <!-- // æ˜¾ç¤º iframe -->
      <!-- document.getElementById('videoIframe5').style.display = 'block'; -->
  <!-- }; -->
<!--  -->
<!--  -->
<!-- </script> -->


<!-- ç”¨äºŽæ·»åŠ æ»‘å—å¯è§†åŒ–å¯¹æ¯”è¿åŠ¨è¡¥å¿æ•ˆæžœ -->
<!-- <script src="static/js/script.js"></script> -->
<!-- <script> -->
  <!-- new BeforeAfter({ -->
      <!-- id: '#example1' -->
  <!-- }); -->
  <!-- new BeforeAfter({ -->
      <!-- id: '#example2' -->
  <!-- }); -->
<!-- </script> -->

</body>
</html>
